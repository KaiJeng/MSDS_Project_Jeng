---
title: "MSDS_Project_Jeng"
author: "Darren Jeng"
date: "November 28, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(stringr)
```

# Video Game Software Sales 2016

(The inital pitch of the project was to compare video game sales and reviews for this current generation, meaning from 2013-current. However, I later realized the site I used to gather sales information does not provide all the sales numbers; the rest require a annual membership fee that cost minimum $4000. Thus, I decided to focus specifically on this year (2016), which allowed more time to refine the UI in the shiny app.)

# Scraping and tidying the data
## Scraping the Score

We will be analyzing video game software sales in 2016, namely determining any correlation between sales numbers and review scores, while observating sales of invidivual titles relative to others via a shiny app. To start, we need to wrangle data for both review scores and sales numbers. Let's start with wrangling review scores by using GameRankings.com. Not only can scrape the review scores, but we can also get the developer and publisher information.  

```{r score}
# Trying to scrape aggrgate score for 2016
url <- "http://www.gamerankings.com/browse.html?site=&cat=0&year=2016&numrev=1&sort=0&letter=&search="
SCORE_GET <- url %>% read_html() %>% html_nodes("table") %>% html_table(fill = TRUE)
SCORE_GET <- as.data.frame(SCORE_GET)
# Rbind for appending the other pages
for (i in 1:9){
  url <- paste("http://www.gamerankings.com/browse.html?page=", i, "&year=2016&numrev=1", sep = "")
  SUBSCORE_GET <- url %>% read_html %>% html_nodes("table") %>% html_table(fill = TRUE)
  SUBSCORE_GET <- as.data.frame(SUBSCORE_GET)
  SCORE_GET <- rbind(SCORE_GET,SUBSCORE_GET)
}
# Start to tidy data set
SCORE_GET$X1 <- NULL
colnames(SCORE_GET)[colnames(SCORE_GET) == "X2"] <- "Platform"
colnames(SCORE_GET)[colnames(SCORE_GET) == "X3"] <- "Game.Untidy"
colnames(SCORE_GET)[colnames(SCORE_GET) == "X4"] <- "Score.Untidy"
# Remove escape sequences
SCORE_GET$Game.Untidy <- str_replace_all(SCORE_GET$Game.Untidy,"\r\n\t\t","$")

# Tidy Game.Untidy to Game, Developer, and Publisher
SCORE_GET <- separate(SCORE_GET, Game.Untidy, into = c("Game", "Info"), sep = "\\$")
SCORE_GET$Info <- str_replace(SCORE_GET$Info,"\\, 2016","")
SCORE_GET$Info <- str_replace(SCORE_GET$Info,"Eighting\\/Raizing", "Eighting")
# Some developers self publish their game which is why a publisher is not listed for those games. Let's fix that. For any row that has N/A in Publisher, copy publisher to developer.
SCORE_GET <- separate(SCORE_GET, Info, into = c("Developer", "Publisher"), sep = "/")
for (i in 1:nrow(SCORE_GET)) {
  if (is.na(SCORE_GET$Publisher[i] == TRUE)) {SCORE_GET$Publisher[i] <- SCORE_GET$Developer[i]}
}
# Tidy Score.Untiy to Score and Number.Of.Reviews
SCORE_GET$Score <- str_extract(SCORE_GET$Score.Untidy,"[0-9]+.[0-9]+")
SCORE_GET$Number.of.Reviews <- str_sub(SCORE_GET$Score.Untidy, 7, 8)
SCORE_GET$Score.Untidy <- NULL

# Peak
head(SCORE_GET)
```

A brief look of the tidy data shows that all of the data was successfully separated. I was not planning to get information about the game (namely developer and publisher) but we can use this data later in our shiny app. 

## Scraping the Sales Numbers

Now, we need to scrape the review scores from VGChartz.com. As noted before, the full sales data is not available unless you are a paid member. Unfortunately, this means that for every week, the first 30 software sales numbers are provided and the other 45 have their numbers redacted. However, a game's position on the chart for that week still gives a general idea of how a game fared. 

(I could have provided an estimate for the other 45 games; for example if game 30 sold 30000 I could have said game 31 to 75 sold <30000. The reason I chose not to is because this estimate will be inflated depending on the shopping season or other factors and wouldn't help provide a clear idea to how many copies the game sold when comparing weeks.)

```{r sales}  
# Getting sales data for software and hardware
url <- "http://www.vgchartz.com/weekly/42372/USA/"
SALES_GET <- url %>% read_html() %>% html_nodes("table") %>% html_table(fill = TRUE)
# There is already a graph for total sales of software and hardware. We can pull that first then worry about individual software next.
# After consideration, console and total software sales data per console will not be used. The focus will be on individual games for the shiny app. However, it is still included for the general analysis section later.
SALES_CONSOLE_GET <- SALES_GET[[154]]
SALES_TOTAL_SOFTWARE_GET <- SALES_GET[[155]]
SALES_WEEKLY_SOFTWARE_GET <- SALES_GET[[2]]
# The data doesn't have the actual date. Using the url, which has code that can be used to interpret the date, I can thus get the date and append this if needed. The number needs to be subtracted by three to reach the same date as on the website. Not entirely sure why this is the case since the data is not being posted three days later but weeks later. 
SALES_WEEKLY_SOFTWARE_GET$Week.Ending <- as.Date(42372 - 3, origin = "1900-01-01")
SALES_CONSOLE_GET$Week.Ending <- as.Date(42372 - 3, origin = "1900-01-01")
SALES_TOTAL_SOFTWARE_GET$Week.Ending <- as.Date(42372 - 3, origin = "1900-01-01")

# With these three data sets initialized, we need a for loop that can extract these three sets for each week until the most current data avaliable. Since the "date" portion of the url just increases by seven, we can just have the loop keep going by intervals of seven until it reaches the most current data. The way this is coded, I could get data for all possible weeks, but instead I am focusing on just this year (2016).
for (i in seq(from = 42379, to = 42694, by = 7)) {
  url <- paste("http://www.vgchartz.com/weekly/", i, "/USA/", sep = "")
  SALES_GET <- url %>% read_html() %>% html_nodes("table") %>% html_table(fill = TRUE)
  SALES_CONSOLE_GET_PART <- SALES_GET[[154]]
  SALES_CONSOLE_GET_PART$Week.Ending <- as.Date(i - 3, origin = "1900-01-01")
  SALES_TOTAL_SOFTWARE_GET_PART <- SALES_GET[[155]]
  SALES_TOTAL_SOFTWARE_GET_PART$Week.Ending <- as.Date(i - 3, origin = "1900-01-01")
  SALES_WEEKLY_SOFTWARE_GET_PART <- SALES_GET[[2]]
  SALES_WEEKLY_SOFTWARE_GET_PART$Week.Ending <- as.Date(i - 3, origin = "1900-01-01")
  
  SALES_CONSOLE_GET <- rbind(SALES_CONSOLE_GET,SALES_CONSOLE_GET_PART)
  SALES_TOTAL_SOFTWARE_GET <- rbind(SALES_TOTAL_SOFTWARE_GET,SALES_TOTAL_SOFTWARE_GET_PART)
  SALES_WEEKLY_SOFTWARE_GET <- rbind(SALES_WEEKLY_SOFTWARE_GET,SALES_WEEKLY_SOFTWARE_GET_PART)
}

# Tidy software sales
names(SALES_WEEKLY_SOFTWARE_GET) <- make.names(names(SALES_WEEKLY_SOFTWARE_GET))
colnames(SALES_WEEKLY_SOFTWARE_GET)[colnames(SALES_WEEKLY_SOFTWARE_GET) == "Weekly"] <- "Remove"
colnames(SALES_WEEKLY_SOFTWARE_GET)[colnames(SALES_WEEKLY_SOFTWARE_GET) == "Total"] <- "Remove2"
colnames(SALES_WEEKLY_SOFTWARE_GET)[colnames(SALES_WEEKLY_SOFTWARE_GET) == "Week.."] <- "Weekly"
names(SALES_WEEKLY_SOFTWARE_GET)[6] <- "Total"
names(SALES_WEEKLY_SOFTWARE_GET)[7] <- "Week.Number"

# Two games are from 2015 and are labeled as such with parenthesis. Change that to brackets for easier separating later on.
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"\\(2015\\)","\\[2015\\]")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"\\(2016\\)","")

# More tidy 
SALES_WEEKLY_SOFTWARE_GET <- separate(SALES_WEEKLY_SOFTWARE_GET, Game, into = c("Game", "Platform.Untidy"), sep = "\\(")
SALES_WEEKLY_SOFTWARE_GET <- separate(SALES_WEEKLY_SOFTWARE_GET, Platform.Untidy, into = c("Platform", "Genre.Untidy"), sep = "\\)")
SALES_WEEKLY_SOFTWARE_GET$Genre <- str_extract(SALES_WEEKLY_SOFTWARE_GET$Genre.Untidy, "\\, [A-z]+\\-?[A-z]*")
SALES_WEEKLY_SOFTWARE_GET$Genre <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Genre,"\\, ","")

# From the beginning after scraping the table had a duplicate line for each observation. Need to filter those out. 
SALES_WEEKLY_SOFTWARE_GET[is.na(SALES_WEEKLY_SOFTWARE_GET)] <- 0
SALES_WEEKLY_SOFTWARE_GET <- filter(SALES_WEEKLY_SOFTWARE_GET, Pos != 0)
SALES_WEEKLY_SOFTWARE_GET <- SALES_WEEKLY_SOFTWARE_GET[,c("Pos", "Game", "Platform", "Genre", "Weekly", "Total", "Week.Number","Week.Ending")]

# Convert numbers from character to integer for later use. Pro and N/A signified that membership was required to get those numbers. Put those to zero first to be later noted.
SALES_WEEKLY_SOFTWARE_GET$Weekly <- str_replace_all(SALES_WEEKLY_SOFTWARE_GET$Weekly,"\\,","")
SALES_WEEKLY_SOFTWARE_GET$Weekly <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Weekly,"Pro","0")
SALES_WEEKLY_SOFTWARE_GET$Weekly <- as.integer(SALES_WEEKLY_SOFTWARE_GET$Weekly)
SALES_WEEKLY_SOFTWARE_GET$Total <- str_replace_all(SALES_WEEKLY_SOFTWARE_GET$Total,"\\,","")
SALES_WEEKLY_SOFTWARE_GET$Total <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Total,"N\\/A","0")
SALES_WEEKLY_SOFTWARE_GET$Total <- as.integer(SALES_WEEKLY_SOFTWARE_GET$Total)

head(SALES_WEEKLY_SOFTWARE_GET)
```

The final tidy data is shown. Now both data sets can be merged into one.

## Merging

Both the review score data (SCORE GET) and sales data (SALES WEEKLY SOFTWARE GET) have variables Platform and Game. We can use these two variables as keys to merge. We use the SCORE_GET datset as the "master" template; this is because that list will have all the games released this year, while sales data will not. Of course, the merge will not work right off the bat, and tweaks were made.

```{r merge and sort}
# For some reason, the names in the SALES_WEEKLY_SOFTWARE_GET data can not be filtered. I don't understand why this is; the class is "character" and str functions work fine with the names but filtering refuses to work. I even tried changing character encodings and that did nothing. Since I can still detect strings in the variable, I can cross reference a name on the review list with the name on the sales list then assign a unique ID for each matching. Then I can join both data sets based on this unique ID as the key.

# I'm dumb; there's a space at the end of each name title. Didn't notice it for the longest time. Removing that, merge works now. 
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game," $","")
SALES_WEEKLY_SOFTWARE_GET$Platform <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Platform,"XOne","XONE")
SALES_WEEKLY_SOFTWARE_GET$Platform <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Platform,"WiiU","WIIU")
SALES_WEEKLY_SOFTWARE_GET$Platform <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Platform,"PSV","VITA")
# Two game has two versions, but sales data doesn't have sales number for each sku. For simplicity, just combine both version into one since their review scores are similar.
SCORE_GET$Game <- str_replace(SCORE_GET$Game,"Pokemon Sun","Pokemon Sun/Moon")
SCORE_GET$Game <- str_replace(SCORE_GET$Game,"Fire Emblem Fates: Special Edition","Fire Emblem Fates")

# Miscelaneious Edits for mismatched titles that I noticed
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"Odin Sphere: Leifdrasir","Odin Sphere Leifthrasir")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"MLB 16: The Show","MLB The Show 16")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"Resident Evil 4 HD","Resident Evil 4")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"Doom","DOOM")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"Rise of the Tomb Raider","Rise of the Tomb Raider 20 Year Celebration")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"Revelator","REVELATOR")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"The Elder Scrolls V Skyrim","The Elder Scrolls V Skyrim Special Edition")
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,"Plants vs. Zombies","Plants vs Zombies")

# Lots of issues with usage of colon in names, and instead of going through each name just remove all of it from both lists. 
SALES_WEEKLY_SOFTWARE_GET$Game <- str_replace(SALES_WEEKLY_SOFTWARE_GET$Game,":","")
SCORE_GET$Game <- str_replace(SCORE_GET$Game,":","")

# Merge the sales data to review scores
SCORE_SALES_ALL <- left_join(SCORE_GET,SALES_WEEKLY_SOFTWARE_GET, by = c("Game","Platform"))
# VGChartz, which provides the sales numbers, also provides the genres. That means if there is no sales data for the game, there is no genre. Make those genres = "unlisted"
SCORE_SALES_ALL$Genre[is.na(SCORE_SALES_ALL$Genre)] <- "Unlisted"
head(SCORE_SALES_ALL)

# Later when we compare scores the best way is to compare first week sales as totals aren't avaiable for many games but first week sales are. Filter into a separate data set now. This dataset is the main one being used (SCORE_SALES_ALL is just for sales numbers).
SALES_WEEKLY_SOFTWARE_WEEKONE <- SALES_WEEKLY_SOFTWARE_GET %>% filter(Week.Number == 1)
SCORE_SALES_WEEKONE <- left_join(SCORE_GET,SALES_WEEKLY_SOFTWARE_WEEKONE, by = c("Game", "Platform"))
SCORE_SALES_WEEKONE$Genre[is.na(SCORE_SALES_WEEKONE$Genre)] <- "Unlisted"
```

The final merged data set is shown above. Using this data, we can compile some analysis on game sales, comparing by platform, by genre, or even publisher. A quick analysis will be provided at the end of this report. But for now, lets move onto building the shiny app.

# Shiny app

(Please refer to the actual app for the full code. Explanations will be provided in this report. Snippets of the code will be shown, so they will not work independently.)
The app focuses on two things: (1) Examing sales data of a specific game (2) Comparision of all the games to one another. Lets start with examing sales data for a specified game.

## Examing a specific game

The basics is to have a textbox allow the user to enter the name of the game and a drop box menu to allow uses to select the correct platform; the description and sales data will output. There are a few issues with this. First, the textbox by default can only take the direct name (meaning the name has to have the exact same capitalization as in the data). Now, some games have the first letter capitalized for each word in their title while others don't. So why not make everying capitalized? A separate variable containing the name of each game but all letters capitalized was created via toupper() function. The input would also be converted using toupper() and matched with this list. We can then output the name with the proper capitalization using the original variable.

```{r}
SCORE_SALES_WEEKONE$Title <- toupper(SCORE_SALES_WEEKONE$Game)
SCORE_SALES_ALL$Title <- toupper(SCORE_SALES_ALL$Game)
```

The other issue is that not every game is released on every platform. I wanted to implement a way for the drop box menu to update depending on what game title was typed in, but that doesn't seem possible. This related to the major issue, dealing with different possible input types. Let's explain each and how to deal with them.

1) The game with no sales numbers (ie Owlboy for PC)
  For the most part, if there are no sales numbers provided for a game by VGChartz.com, it is either because the game was not tracked by VGChartz.com or it was a digital release (digital sales numbers are not disclosed because they can't be tracked unless you are the original seller). Thus, these games will still have descriptions but no sales data graph. We can identify these games by using the Total variable; clearly since the game has no sales data, the total will be N/A. Any game that fits in this category will have a warning message indicating "Sales data unavailbe for this title" in the Sales Numbers tab on top. Description will output as normal
  
```{r}
for (i in 1:nrow(SCORE_SALES_WEEKONE)) {
  if (is.na(SCORE_SALES_WEEKONE$Total[i] == FALSE)) {SCORE_SALES_WEEKONE$Complicated[i] <- "Sales data below:"}
  if (is.na(SCORE_SALES_WEEKONE$Total[i] == TRUE)) {SCORE_SALES_WEEKONE$Complicated[i] <- "Sales data unavailable for this title."}
}

# Shiny app needs datasets, so write the csvs in a separate file to be called later. Commented out so it won't write it but you can see the step.
# write.csv(SCORE_SALES_ALL, file = "~/Documents/MSDS597/MSDS Project/data/Score_Sales_All")
# write.csv(SCORE_SALES_WEEKONE, file = "~/Documents/MSDS597/MSDS Project/data/Score_Sales_Week_One")
```
  
2) The game with sales numbers but incorrect platform (ie Overwatch for Nintendo Wii U)
  The data table will indicate that data is unavailable. Since it seems like rstudio won't let me check the resulting reactive dataset after user input (which would make things alot easier), I can't implement a notification similar to what I did earlier which ignored user input. Regardless, if the user picks a correct game but wrong platform no information will show.

3) The game with sales numbers and correct platform (ie Doom for Playstation 4)
  Description and sales numbers will output whatever data is available.
  
With the possible inputs taken care of, lets explain comparison function in the app.

## Comparison of all games to one another

Since sales data is limited, the best way for comparison is to compare the first week sales of all games. A basic data table with extra filters is provided for the user to customize their own comparison methods. The other tab brings us back to the original analysis of review score vs. sales. A plot of score vs sales is shown as well as the data table. The difference with this data table is that you can select an observation and it will be highlighted in the plot. This way, a person can compare games visually through a plot.

Please try the shiny app to see all of the things described in action.

# Analysis of the data

```{r}
# Quick set up for data (this is done in the shiny app)
SCORE_SALES_VS <- SCORE_SALES_WEEKONE %>% filter(Complicated == "Sales data below:", Weekly != 0)
ggplot(SCORE_SALES_VS, aes(Score, Weekly)) + geom_point() + xlab("Review Score") + ylab("Sales Numbers")
```

Looking at this plot (better plot in the shiny app, using that as reference), there isn't a "real" trend but some things can be observed. The basic idea is that generally the game needs to have a higher score to get higher first week sales. But what happens when many games have higher scores?  This year has seen the release of many good games (scores of 70+), much more than previous years. You can see a notable cluster of games near the 80+ score range. Unfortunately, only a couple of those games actually hit higher first week sales while the rest average low first week sales. This is reflected in monthly sales reports where software sales are down from last year for most of 2016 so far. Even according to the most recent report, software sales are down in November, which is when spending happens the most. Games are getting better yet sales are not reflecting the quality. 

The big flaw of course is using first week sales as the gauge. If you look at a game like Titanfall 2 for Playstation 4 (PS4), you can see sales picking up and even exceeding its first week sales record. So it's still possible that higher scoring games sell more in the long run as compared to lower scoring games. But what can be said is review scores don't impact first week sales as much as one would expect.

```{r}
names(SALES_TOTAL_SOFTWARE_GET)[2] <- "Sales" 
names(SALES_TOTAL_SOFTWARE_GET)[3] <- "Percent.Change"
SALES_TOTAL_SOFTWARE_GET$Sales <- str_replace_all(SALES_TOTAL_SOFTWARE_GET$Sales,",","")
SALES_TOTAL_SOFTWARE_GET$Sales <- as.numeric(SALES_TOTAL_SOFTWARE_GET$Sales)
SALES_TOTAL_SOFTWARE_GET$Percent.Change <- str_extract(SALES_TOTAL_SOFTWARE_GET$Percent.Change,"\\-?\\+?[0-9]+")
SALES_TOTAL_SOFTWARE_GET$Percent.Change <- as.numeric(SALES_TOTAL_SOFTWARE_GET$Percent.Change)
SALES_TOTAL_SOFTWARE_ALL <- SALES_TOTAL_SOFTWARE_GET %>% filter(Platform == "Total")
ggplot(SALES_TOTAL_SOFTWARE_ALL, aes(Week.Ending, Sales)) + geom_point() + ggtitle("Total software sales per week") + scale_x_date()
```

Another interesting look is general shopping for video games (of course using one year's data doesn't allow for general trends but if you look at the past years, which I did do separately by changing the scrapping url loop, it's practically the same yearly). The summer is a great time to go outside but it also is a great time to stay indoors and not bake in the sun. Yet video games don't sell much in the summer. Summer is also the time when school is out so its interesting that games sell the most when school is in session. Holiday is the huge boom of video game sales and does emphasize the flaw of using first week sales for comparisons since games could definitely sell more in the holiday season compared to their first week. 

